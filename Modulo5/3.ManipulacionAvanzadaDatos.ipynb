{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulación Avanzada de Datos\n",
    "------------------------\n",
    "\n",
    "En esta sección aprenderemos a manipular nuestro dataframe haciendo agrupaciones de datos o trabajando con más de un dataframe a la vez\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sumarización de Datos\n",
    "\n",
    "Las sentencias de agrupamiento de datos nos ayudan a brindar información resumida que pueda ser facilmente analizada por diversas personas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/group_by.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El agrupamiento de datos implica utilizar funciones de agregacion como: `count`, `sum`, `mean`, `min`, `max` a una columna del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_reviews = pd.read_csv('./src/winemag-data-130k-v2.csv')\n",
    "df_reviews.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# groupby -> lista de columnas a agrupar\n",
    "df_reviews.groupby(['country']).price.agg([len, 'min', 'max', 'mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = df_reviews.groupby(['country', 'province']).agg(\n",
    "    # columna: metosdos agregacion a aplicar\n",
    "    {'points': ['mean', 'min', 'max'],\n",
    "     'price': ['mean', 'min', 'max']\n",
    "    }\n",
    "    # ordenando por points descendentemente y price ascendentemente\n",
    ").sort_values(by=[('points', 'mean'), ('price', 'mean')], ascending=[False, True])\n",
    "\n",
    "# mostrando top 5\n",
    "df_group.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Manipulando más de un DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Unificando o Concatenando DataFrames\n",
    "\n",
    "Esto nos permite unificar información de Dataframs cuyas columnas sean iguales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://pandas.pydata.org/docs/_images/08_concat_row.svg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A manera de ejemplo veremos la unificación de 2 df's cuya data es similar\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "columns = [\"date.utc\", \"location\", \"parameter\", \"value\"]\n",
    "\n",
    "df_air_quality_no2 = pd.read_csv(\"./src/air_quality_no2_long.csv\", parse_dates=True, usecols=columns)\n",
    "df_air_quality_pm25 = pd.read_csv(\"./src/air_quality_pm25_long.csv\", parse_dates=True, usecols=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air_quality_no2.head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air_quality_pm25.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unificando la información en un único df\n",
    "\n",
    "df_air_quality = pd.concat([df_air_quality_pm25, df_air_quality_no2], axis=0)\n",
    "df_air_quality.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrección del índice\n",
    "df_air_quality = df_air_quality.reset_index(drop=True)\n",
    "df_air_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of the ``air_quality_pm25`` table: ', df_air_quality_pm25.shape)\n",
    "\n",
    "print('Shape of the ``air_quality_no2`` table: ', df_air_quality_no2.shape)\n",
    "\n",
    "print('Shape of the resulting ``air_quality`` table: ', df_air_quality.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos unir dos dataframes en funcion de sus columnas comunes usando `merge`\n",
    "\n",
    "La operacion merge implica combinar 2 df a partir de uno o más valores llave o `key`\n",
    "\n",
    "<img src='./img/merge.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unificaremos la información consolidada del df previo \n",
    "df_stations_coord = pd.read_csv(\"./src/air_quality_stations.csv\")\n",
    "df_stations_coord.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations_coord.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos damos cuenta que existen valores duplicados sobre el campo llave de 'location'\n",
    "df_stations_coord.drop_duplicates(subset=['location']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations_coord_no_duplicates = df_stations_coord.drop_duplicates(subset=['location'], keep='first')\n",
    "df_stations_coord_no_duplicates.reset_index(inplace=True,drop=True)\n",
    "df_stations_coord_no_duplicates.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# como llame emplearemos la columna 'location'\n",
    "\n",
    "df_air_quality = pd.merge(df_air_quality, df_stations_coord_no_duplicates, how=\"inner\", on=\"location\")\n",
    "df_air_quality.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notamos un incremento de los registros, luego del inner join\n",
    "df_air_quality.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# como llave emplearemos la columna 'location'\n",
    "df_air_quality_2 = pd.merge(df_air_quality, df_stations_coord_no_duplicates, how=\"inner\", left_on='location', right_on='location')\n",
    "\n",
    "df_air_quality_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como punto general existen diferentes formas de combinar los dataframe, siendo el método `inner` el utilizado por defecto\n",
    "\n",
    "<img src='./img/merge_tipos.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información Adicional\n",
    "\n",
    "\n",
    "- Group By Explicado:  https://learnsql.com/blog/group-by-in-sql-explained/\n",
    "\n",
    "- Combinando Múltiples dataFrames : https://pandas.pydata.org/docs/getting_started/intro_tutorials/08_combine_dataframes.html#min-tut-08-combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolviendo PC4 - Ejercicio 5 del examen.\n",
    "# Empleando Pandas\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from pymongoarrow.api import Schema\n",
    "from pymongoarrow.monkey import patch_all\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "\n",
    "RUTA_ARCHIVO = '/workspaces/ProgramacionPython202506/Modulo4/src/ventas.csv'\n",
    "# Configura los detalles de conexión\n",
    "RUTA_CADENA_CONEXION = \"/workspaces/ProgramacionPython202506/Modulo4/scripts/problema4/cadena.txt\"\n",
    "mongo_uri = open(RUTA_CADENA_CONEXION).read().strip()\n",
    "\n",
    "# Aplica el monkey patch para usar pymongoarrow\n",
    "patch_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nombres_columnas = ['fecha_venta', 'product_name', 'cantidad', 'precio']\n",
    "df_ventas =  pd.read_csv(RUTA_ARCHIVO, sep=',', header=None)\n",
    "\n",
    "# renombrando columnas\n",
    "df_ventas.columns = nombres_columnas\n",
    "\n",
    "df_ventas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traer informacion de TC de MongoDB\n",
    "\n",
    "with MongoClient(mongo_uri) as client:\n",
    "    # Selecciona la base de datos y la colección\n",
    "    db = client['curso_db']\n",
    "    collection = db['sunat']\n",
    "\n",
    "    # Define el esquema para los datos que quieres leer\n",
    "    # schema = Schema({\"campo1\": pa.string(), \"campo2\": pa.int64(), \"campo3\": pa.float64()})\n",
    "\n",
    "    # Lee los datos desde MongoDB en un DataFrame de pandas usando pymongoarrow\n",
    "    df_tc = collection.find_pandas_all({})\n",
    "    pass\n",
    "\n",
    "df_tc.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizo operacion de merge de los df \n",
    "\n",
    "df_ventas_consolidado = pd.merge(df_ventas, df_tc, how='left', left_on='fecha_venta', right_on='fecha')\n",
    "\n",
    "df_ventas_consolidado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminamos columnas que no son de interes\n",
    "\n",
    "df_ventas_consolidado.drop(columns=['_id','origen','moneda','fecha'], inplace=True, axis=0)\n",
    "df_ventas_consolidado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas_consolidado['precio_solarizado'] = df_ventas_consolidado.precio * df_ventas_consolidado.venta\n",
    "df_ventas_consolidado['subtotal'] = df_ventas_consolidado.precio_solarizado * df_ventas_consolidado.cantidad\n",
    "df_ventas_consolidado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupago = df_ventas_consolidado.groupby(['product_name']).agg(\n",
    "    {'subtotal': 'sum'}\n",
    ")\n",
    "df_agrupago"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
